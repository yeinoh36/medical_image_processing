{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Setup\n","\n","\n","\n","\n"],"metadata":{"id":"bnWAqMpeDaCQ"}},{"cell_type":"code","source":["!pip install tensorflow-addons\n","import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers, models\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","import tensorflow_addons as tfa"],"metadata":{"id":"pwRvynVI4hPg","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3967ff70-cfdf-4eb4-abf9-7c1bdbeed2d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/611.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/611.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m604.2/611.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.2)\n","Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Installing collected packages: typeguard, tensorflow-addons\n","Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["# Prepare the data"],"metadata":{"id":"GtoI_M754kHy"}},{"cell_type":"code","source":["\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","# 작업 경로를 my drive로 변경하여 구글 드라이브 접속 후 작업 경로 확인\n","print('현재 작업 경로 :', os.getcwd())\n","os.chdir('/content/drive/MyDrive/')\n","print('변경된 작업 경로 :', os.getcwd())\n","\n","# 이미지 데이터를 저장한 폴더 경로\n","data_folder = \"/content/drive/MyDrive/dataset\"\n","\n","# 이미지를 로드하고 NumPy 배열로 변환하는 함수\n","def load_and_preprocess_image(image_path, target_size=(128, 128)):\n","    img = load_img(image_path, target_size=target_size)\n","    img_array = img_to_array(img)\n","    img_array /= 255.0  # 이미지를 [0, 1] 범위로 정규화\n","    return img_array\n","\n","\n","\n","# 데이터 생성\n","data = []\n","\n","# 폴더 탐색\n","for root, dirs, files in os.walk(data_folder):\n","    for file in files:\n","        if file.endswith((\".jpg\", \".jpeg\", \".png\")):\n","            # 이미지 파일 경로\n","            image_path = os.path.join(root, file)\n","\n","            # 레이블 (폴더 이름을 사용할 수도 있음)\n","            label = os.path.basename(root)\n","\n","            # 데이터 딕셔너리에 추가\n","            data.append({\"image_path\": image_path, \"label\": label})\n","\n","\n","images = []\n","labels = []\n","\n","for sample in data:\n","    image_path = sample[\"image_path\"]\n","    label = sample[\"label\"]\n","\n","    img_array = load_and_preprocess_image(image_path)\n","    images.append(img_array)\n","    labels.append(label)\n","\n","\n","# 이미지 데이터를 NumPy 배열로 변환\n","images = np.array(images)\n","labels = np.array(labels)\n","\n","# 레이블을 숫자로 인코딩\n","label_encoder = LabelEncoder()\n","encoded_labels = label_encoder.fit_transform(labels)\n","\n","# 레이블을 원-핫 인코딩\n","num_classes = len(np.unique(encoded_labels))\n","one_hot_labels = tf.keras.utils.to_categorical(encoded_labels, num_classes)\n","\n","\n","# 훈련 및 테스트 세트로 데이터 분할\n","train_images, test_images, train_labels, test_labels = train_test_split(\n","    images, one_hot_labels, test_size=0.2, random_state=42\n",")\n","\n","# 데이터 형태 확인\n","print(\"Train images shape:\", train_images.shape)\n","print(\"Train labels shape:\", train_labels.shape)\n","print(\"Test images shape:\", test_images.shape)\n","print(\"Test labels shape:\", test_labels.shape)"],"metadata":{"id":"A8pbXgxB4nUB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"50a392bf-8171-4902-91e0-a34447473675"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n","현재 작업 경로 : /content\n","변경된 작업 경로 : /content/drive/MyDrive\n","Train images shape: (556, 128, 128, 3)\n","Train labels shape: (556, 2)\n","Test images shape: (140, 128, 128, 3)\n","Test labels shape: (140, 2)\n"]}]},{"cell_type":"markdown","source":["# Modeling 1"],"metadata":{"id":"zA34v2CzpERX"}},{"cell_type":"code","source":["# MLP 모델 정의\n","\n","from keras.layers import BatchNormalization\n","from keras.regularizers import l2\n","from keras.callbacks import EarlyStopping\n","\n","# Assuming your input shape is (img_height, img_width, num_channels)\n","input_shape = (128, 128, 3)\n","\n","model = keras.Sequential([\n","    keras.layers.Flatten(input_shape=input_shape),\n","    BatchNormalization(),  # Add Batch Normalization before the activation function\n","    keras.layers.Dense(512, activation='relu', kernel_regularizer=l2(0.01)),\n","    keras.layers.Dropout(0.5),\n","    keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n","    keras.layers.Dropout(0.5),\n","    keras.layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n","    keras.layers.Dropout(0.2),\n","    keras.layers.Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n","    keras.layers.Dropout(0.2),\n","    keras.layers.Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n","    keras.layers.Dropout(0.2),\n","    keras.layers.Dense(2, activation='softmax')\n","])\n","\n","# 모델 컴파일\n","optimizer = keras.optimizers.Adam(learning_rate=0.0003)\n","model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# 모델 요약 출력\n","model.summary()\n","\n","model.fit(train_images, train_labels, epochs=100, batch_size=10)\n","model.evaluate(test_images, test_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hlgJr9mRiYdt","outputId":"86f48431-9b4e-4c4f-bf39-118c35566b18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_1 (Flatten)         (None, 49152)             0         \n","                                                                 \n"," batch_normalization_1 (Bat  (None, 49152)             196608    \n"," chNormalization)                                                \n","                                                                 \n"," dense_6 (Dense)             (None, 512)               25166336  \n","                                                                 \n"," dropout_5 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_7 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dropout_6 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_8 (Dense)             (None, 128)               32896     \n","                                                                 \n"," dropout_7 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_9 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dropout_8 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_10 (Dense)            (None, 32)                2080      \n","                                                                 \n"," dropout_9 (Dropout)         (None, 32)                0         \n","                                                                 \n"," dense_11 (Dense)            (None, 2)                 66        \n","                                                                 \n","=================================================================\n","Total params: 25537570 (97.42 MB)\n","Trainable params: 25439266 (97.04 MB)\n","Non-trainable params: 98304 (384.00 KB)\n","_________________________________________________________________\n","Epoch 1/100\n","56/56 [==============================] - 34s 566ms/step - loss: 19.2889 - accuracy: 0.4946\n","Epoch 2/100\n","56/56 [==============================] - 30s 529ms/step - loss: 17.9456 - accuracy: 0.5450\n","Epoch 3/100\n","56/56 [==============================] - 32s 562ms/step - loss: 16.9392 - accuracy: 0.5090\n","Epoch 4/100\n","56/56 [==============================] - 32s 571ms/step - loss: 15.7363 - accuracy: 0.5306\n","Epoch 5/100\n","56/56 [==============================] - 31s 563ms/step - loss: 14.7352 - accuracy: 0.5324\n","Epoch 6/100\n","56/56 [==============================] - 29s 523ms/step - loss: 13.8300 - accuracy: 0.5234\n","Epoch 7/100\n","56/56 [==============================] - 32s 563ms/step - loss: 12.8974 - accuracy: 0.5198\n","Epoch 8/100\n","56/56 [==============================] - 32s 570ms/step - loss: 11.9053 - accuracy: 0.4928\n","Epoch 9/100\n","56/56 [==============================] - 31s 563ms/step - loss: 10.9905 - accuracy: 0.5054\n","Epoch 10/100\n","56/56 [==============================] - 30s 526ms/step - loss: 10.1813 - accuracy: 0.5198\n","Epoch 11/100\n","56/56 [==============================] - 32s 564ms/step - loss: 9.5272 - accuracy: 0.5486\n","Epoch 12/100\n","56/56 [==============================] - 32s 569ms/step - loss: 8.9339 - accuracy: 0.5180\n","Epoch 13/100\n","56/56 [==============================] - 31s 561ms/step - loss: 8.4253 - accuracy: 0.5522\n","Epoch 14/100\n","56/56 [==============================] - 30s 531ms/step - loss: 7.9928 - accuracy: 0.5360\n","Epoch 15/100\n","56/56 [==============================] - 32s 560ms/step - loss: 7.5948 - accuracy: 0.5144\n","Epoch 16/100\n","56/56 [==============================] - 32s 572ms/step - loss: 7.1952 - accuracy: 0.6151\n","Epoch 17/100\n","56/56 [==============================] - 31s 558ms/step - loss: 6.9389 - accuracy: 0.5486\n","Epoch 18/100\n","56/56 [==============================] - 30s 533ms/step - loss: 6.6793 - accuracy: 0.5486\n","Epoch 19/100\n","56/56 [==============================] - 32s 562ms/step - loss: 6.4811 - accuracy: 0.5522\n","Epoch 20/100\n","56/56 [==============================] - 32s 572ms/step - loss: 6.2633 - accuracy: 0.5414\n","Epoch 21/100\n","56/56 [==============================] - 32s 569ms/step - loss: 6.0185 - accuracy: 0.5719\n","Epoch 22/100\n","56/56 [==============================] - 30s 539ms/step - loss: 5.8269 - accuracy: 0.5827\n","Epoch 23/100\n","56/56 [==============================] - 31s 549ms/step - loss: 5.6842 - accuracy: 0.5647\n","Epoch 24/100\n","56/56 [==============================] - 32s 570ms/step - loss: 5.5625 - accuracy: 0.5558\n","Epoch 25/100\n","56/56 [==============================] - 32s 569ms/step - loss: 5.4144 - accuracy: 0.5971\n","Epoch 26/100\n","56/56 [==============================] - 30s 537ms/step - loss: 5.2630 - accuracy: 0.6205\n","Epoch 27/100\n","56/56 [==============================] - 31s 552ms/step - loss: 5.2053 - accuracy: 0.5629\n","Epoch 28/100\n","56/56 [==============================] - 32s 576ms/step - loss: 5.1289 - accuracy: 0.6043\n","Epoch 29/100\n","56/56 [==============================] - 32s 573ms/step - loss: 5.0357 - accuracy: 0.6115\n","Epoch 30/100\n","56/56 [==============================] - 31s 548ms/step - loss: 4.9314 - accuracy: 0.6349\n","Epoch 31/100\n","56/56 [==============================] - 31s 544ms/step - loss: 4.8397 - accuracy: 0.6493\n","Epoch 32/100\n","56/56 [==============================] - 32s 577ms/step - loss: 4.7613 - accuracy: 0.6493\n","Epoch 33/100\n","56/56 [==============================] - 32s 573ms/step - loss: 4.6241 - accuracy: 0.6924\n","Epoch 34/100\n","56/56 [==============================] - 31s 553ms/step - loss: 4.6428 - accuracy: 0.6960\n","Epoch 35/100\n","56/56 [==============================] - 31s 543ms/step - loss: 4.7043 - accuracy: 0.6960\n","Epoch 36/100\n","56/56 [==============================] - 32s 577ms/step - loss: 4.6324 - accuracy: 0.7014\n","Epoch 37/100\n","56/56 [==============================] - 32s 580ms/step - loss: 4.5270 - accuracy: 0.7050\n","Epoch 38/100\n","56/56 [==============================] - 32s 568ms/step - loss: 4.4170 - accuracy: 0.7140\n","Epoch 39/100\n","56/56 [==============================] - 30s 540ms/step - loss: 4.3160 - accuracy: 0.7464\n","Epoch 40/100\n","56/56 [==============================] - 32s 563ms/step - loss: 4.2325 - accuracy: 0.7554\n","Epoch 41/100\n","56/56 [==============================] - 32s 576ms/step - loss: 4.0745 - accuracy: 0.7356\n","Epoch 42/100\n","56/56 [==============================] - 32s 575ms/step - loss: 4.0144 - accuracy: 0.7482\n","Epoch 43/100\n","56/56 [==============================] - 31s 550ms/step - loss: 3.8920 - accuracy: 0.7446\n","Epoch 44/100\n","56/56 [==============================] - 31s 549ms/step - loss: 4.0387 - accuracy: 0.7158\n","Epoch 45/100\n","56/56 [==============================] - 32s 574ms/step - loss: 3.6377 - accuracy: 0.7626\n","Epoch 46/100\n","56/56 [==============================] - 32s 571ms/step - loss: 3.5589 - accuracy: 0.7788\n","Epoch 47/100\n","56/56 [==============================] - 31s 557ms/step - loss: 3.5349 - accuracy: 0.7500\n","Epoch 48/100\n","56/56 [==============================] - 30s 538ms/step - loss: 3.5552 - accuracy: 0.7014\n","Epoch 49/100\n","56/56 [==============================] - 32s 572ms/step - loss: 3.3571 - accuracy: 0.7572\n","Epoch 50/100\n","56/56 [==============================] - 32s 572ms/step - loss: 3.3707 - accuracy: 0.7680\n","Epoch 51/100\n","56/56 [==============================] - 32s 569ms/step - loss: 3.4065 - accuracy: 0.7230\n","Epoch 52/100\n","56/56 [==============================] - 30s 534ms/step - loss: 3.2971 - accuracy: 0.7608\n","Epoch 53/100\n","56/56 [==============================] - 32s 560ms/step - loss: 2.9838 - accuracy: 0.7878\n","Epoch 54/100\n","56/56 [==============================] - 32s 573ms/step - loss: 3.0490 - accuracy: 0.7536\n","Epoch 55/100\n","56/56 [==============================] - 32s 579ms/step - loss: 2.9687 - accuracy: 0.7698\n","Epoch 56/100\n","56/56 [==============================] - 31s 562ms/step - loss: 2.7986 - accuracy: 0.7680\n","Epoch 57/100\n","56/56 [==============================] - 32s 560ms/step - loss: 2.8595 - accuracy: 0.7770\n","Epoch 58/100\n","56/56 [==============================] - 33s 596ms/step - loss: 2.9192 - accuracy: 0.7248\n","Epoch 59/100\n","56/56 [==============================] - 33s 599ms/step - loss: 2.6805 - accuracy: 0.7644\n","Epoch 60/100\n","56/56 [==============================] - 36s 645ms/step - loss: 2.6240 - accuracy: 0.7842\n","Epoch 61/100\n","56/56 [==============================] - 34s 601ms/step - loss: 2.7092 - accuracy: 0.7374\n","Epoch 62/100\n","56/56 [==============================] - 33s 588ms/step - loss: 2.5940 - accuracy: 0.7608\n","Epoch 63/100\n","56/56 [==============================] - 31s 552ms/step - loss: 2.4741 - accuracy: 0.7680\n","Epoch 64/100\n","56/56 [==============================] - 32s 570ms/step - loss: 2.3111 - accuracy: 0.7680\n","Epoch 65/100\n","56/56 [==============================] - 33s 587ms/step - loss: 2.2344 - accuracy: 0.7680\n","Epoch 66/100\n","56/56 [==============================] - 33s 582ms/step - loss: 2.2131 - accuracy: 0.7428\n","Epoch 67/100\n","56/56 [==============================] - 32s 581ms/step - loss: 2.1135 - accuracy: 0.7716\n","Epoch 68/100\n","56/56 [==============================] - 31s 544ms/step - loss: 2.1634 - accuracy: 0.7518\n","Epoch 69/100\n","56/56 [==============================] - 32s 566ms/step - loss: 2.1468 - accuracy: 0.7572\n","Epoch 70/100\n","56/56 [==============================] - 32s 578ms/step - loss: 1.9634 - accuracy: 0.8112\n","Epoch 71/100\n","56/56 [==============================] - 32s 578ms/step - loss: 2.1895 - accuracy: 0.7482\n","Epoch 72/100\n","56/56 [==============================] - 31s 552ms/step - loss: 2.0232 - accuracy: 0.7626\n","Epoch 73/100\n","56/56 [==============================] - 31s 543ms/step - loss: 1.8542 - accuracy: 0.7860\n","Epoch 74/100\n","56/56 [==============================] - 32s 572ms/step - loss: 1.9181 - accuracy: 0.7842\n","Epoch 75/100\n","56/56 [==============================] - 32s 573ms/step - loss: 1.8381 - accuracy: 0.7824\n","Epoch 76/100\n","56/56 [==============================] - 31s 551ms/step - loss: 1.8583 - accuracy: 0.7572\n","Epoch 77/100\n","56/56 [==============================] - 30s 539ms/step - loss: 1.8307 - accuracy: 0.7608\n","Epoch 78/100\n","56/56 [==============================] - 32s 570ms/step - loss: 1.6770 - accuracy: 0.7824\n","Epoch 79/100\n","56/56 [==============================] - 32s 572ms/step - loss: 1.6147 - accuracy: 0.7986\n","Epoch 80/100\n","56/56 [==============================] - 31s 562ms/step - loss: 1.6722 - accuracy: 0.7662\n","Epoch 81/100\n","56/56 [==============================] - 31s 545ms/step - loss: 1.6296 - accuracy: 0.7878\n","Epoch 82/100\n","56/56 [==============================] - 33s 590ms/step - loss: 1.4782 - accuracy: 0.7986\n","Epoch 83/100\n","56/56 [==============================] - 32s 582ms/step - loss: 1.6622 - accuracy: 0.7626\n","Epoch 84/100\n","56/56 [==============================] - 32s 580ms/step - loss: 1.6551 - accuracy: 0.7662\n","Epoch 85/100\n","56/56 [==============================] - 31s 553ms/step - loss: 1.4352 - accuracy: 0.8004\n","Epoch 86/100\n","56/56 [==============================] - 33s 592ms/step - loss: 1.4767 - accuracy: 0.8058\n","Epoch 87/100\n","56/56 [==============================] - 34s 597ms/step - loss: 1.5325 - accuracy: 0.7860\n","Epoch 88/100\n","56/56 [==============================] - 33s 593ms/step - loss: 1.4439 - accuracy: 0.7932\n","Epoch 89/100\n","56/56 [==============================] - 33s 583ms/step - loss: 1.4795 - accuracy: 0.7698\n","Epoch 90/100\n","56/56 [==============================] - 33s 584ms/step - loss: 1.3696 - accuracy: 0.7770\n","Epoch 91/100\n","56/56 [==============================] - 31s 552ms/step - loss: 1.3343 - accuracy: 0.7860\n","Epoch 92/100\n","56/56 [==============================] - 32s 559ms/step - loss: 1.2875 - accuracy: 0.7950\n","Epoch 93/100\n","56/56 [==============================] - 32s 580ms/step - loss: 1.3267 - accuracy: 0.7734\n","Epoch 94/100\n","56/56 [==============================] - 32s 580ms/step - loss: 1.2844 - accuracy: 0.7968\n","Epoch 95/100\n","56/56 [==============================] - 32s 574ms/step - loss: 1.1530 - accuracy: 0.8273\n","Epoch 96/100\n","56/56 [==============================] - 31s 544ms/step - loss: 1.2980 - accuracy: 0.7788\n","Epoch 97/100\n","56/56 [==============================] - 31s 558ms/step - loss: 1.4537 - accuracy: 0.7374\n","Epoch 98/100\n","56/56 [==============================] - 33s 583ms/step - loss: 1.3418 - accuracy: 0.7464\n","Epoch 99/100\n","56/56 [==============================] - 32s 577ms/step - loss: 1.1514 - accuracy: 0.8004\n","Epoch 100/100\n","56/56 [==============================] - 31s 564ms/step - loss: 1.1147 - accuracy: 0.8273\n","5/5 [==============================] - 1s 55ms/step - loss: 1.6859 - accuracy: 0.5143\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.6858874559402466, 0.5142857432365417]"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["model.evaluate(test_images, test_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QpMa0CClo69y","outputId":"79687962-6e00-4561-80f6-577853759b99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5/5 [==============================] - 0s 55ms/step - loss: 1.6859 - accuracy: 0.5143\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.6858874559402466, 0.5142857432365417]"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["# Confusion Matrix"],"metadata":{"id":"Ma2JHY5tiq4g"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, classification_report\n","import numpy as np\n","\n","# 테스트 데이터에 대한 예측값 생성\n","predictions = model.predict(test_images)\n","\n","# 예측값을 클래스로 변환\n","predicted_classes = np.argmax(predictions, axis=1)\n","\n","# 실제 레이블을 클래스로 변환\n","true_classes = np.argmax(test_labels, axis=1)\n","\n","# Confusion matrix 계산\n","cm = confusion_matrix(true_classes, predicted_classes)\n","\n","# TP, FN, FP, TN 출력\n","print(\"\\nConfusion Matrix:\")\n","print(\"================================\")\n","print(\"                Predicted Positive | Predicted Negative\")\n","print(\"--------------------------------|-------------------\")\n","print(f\"Actual Positive | {cm[1,1]:<16} | {cm[1,0]:<16}\")\n","print(\"--------------------------------|-------------------\")\n","print(f\"Actual Negative | {cm[0,1]:<16} | {cm[0,0]:<16}\")\n","print(\"================================\")\n","\n","# True Positive (TP)\n","tp = cm[1, 1]\n","\n","# False Positive (FP)\n","fp = cm[0, 1]\n","\n","# True Negative (TN)\n","tn = cm[0, 0]\n","\n","# False Negative (FN)\n","fn = cm[1, 0]\n","\n","# True Positive Rate (Sensitivity, Recall, TPR)\n","tpr = tp / (tp + fn)\n","\n","# False Positive Rate (FPR)\n","fpr = fp / (fp + tn)\n","\n","# True Negative Rate (Specificity, TNR)\n","tnr = tn / (tn + fp)\n","\n","# False Negative Rate (FNR)\n","fnr = fn / (fn + tp)\n","\n","# 출력\n","print(\"\\nPerformance Metrics:\")\n","print(\"===============================\")\n","print(f\"True Positive Rate (TPR): {tpr}\")\n","print(f\"False Positive Rate (FPR): {fpr}\")\n","print(f\"True Negative Rate (TNR): {tnr}\")\n","print(f\"False Negative Rate (FNR): {fnr}\")\n","print(\"===============================\")\n","\n","# classification report 출력\n","print(\"Confusion Matrix:\")\n","print(cm)\n","\n","# classification report 출력\n","print(\"\\nClassification Report:\")\n","print(classification_report(true_classes, predicted_classes))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CYcRKTLsiu9Z","outputId":"c25fba96-b3a0-4050-aae2-7961e4893d6e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5/5 [==============================] - 0s 82ms/step\n","\n","Confusion Matrix:\n","================================\n","                Predicted Positive | Predicted Negative\n","--------------------------------|-------------------\n","Actual Positive | 11               | 67              \n","--------------------------------|-------------------\n","Actual Negative | 1                | 61              \n","================================\n","\n","Performance Metrics:\n","===============================\n","True Positive Rate (TPR): 0.14102564102564102\n","False Positive Rate (FPR): 0.016129032258064516\n","True Negative Rate (TNR): 0.9838709677419355\n","False Negative Rate (FNR): 0.8589743589743589\n","===============================\n","Confusion Matrix:\n","[[61  1]\n"," [67 11]]\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.48      0.98      0.64        62\n","           1       0.92      0.14      0.24        78\n","\n","    accuracy                           0.51       140\n","   macro avg       0.70      0.56      0.44       140\n","weighted avg       0.72      0.51      0.42       140\n","\n"]}]}]}