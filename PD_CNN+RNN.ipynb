{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/tensorflow/docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erdTvisRO76x",
        "outputId": "cd0a686f-20d7-40fb-941b-b8b4fbfe3b53"
      },
      "id": "erdTvisRO76x",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# 작업 경로를 my drive로 변경하여 구글 드라이브 접속 후 작업 경로 확인\n",
        "print('현재 작업 경로 :', os.getcwd())\n",
        "os.chdir('/content/drive/MyDrive')\n",
        "print('변경된 작업 경로 :', os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4ZjuQubBJGw",
        "outputId": "c85f840f-5e6a-47f4-a5eb-dfe53a88749e"
      },
      "id": "P4ZjuQubBJGw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "현재 작업 경로 : /content\n",
            "변경된 작업 경로 : /content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout"
      ],
      "metadata": {
        "id": "Njc8i3Y7NLh_"
      },
      "id": "Njc8i3Y7NLh_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 데이터를 로드하고 전처리하는 함수\n",
        "def load_images(directory, label):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".png\"):\n",
        "            img_path = os.path.join(directory, filename)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # 흑백 이미지 사용\n",
        "            img = cv2.resize(img, (64, 64))\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "ByQiWH1ICPVP"
      },
      "id": "ByQiWH1ICPVP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드 및 전처리\n",
        "patients_images, patients_labels = load_images(\"/content/drive/MyDrive/dataset/patients\", label=\"patients\")\n",
        "controls_images, controls_labels = load_images(\"/content/drive/MyDrive/dataset/controls\", label=\"controls\")\n",
        "\n",
        "# 데이터 합치기\n",
        "X = np.array(patients_images + controls_images)\n",
        "y = np.array(patients_labels + controls_labels)\n",
        "\n",
        "# 레이블을 숫자로 인코딩\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# 데이터를 학습 세트와 테스트 세트로 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 테스트 세트를 더 나눠서 검증 세트로 분리\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
        "\n",
        "# 데이터 전처리\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_val = X_val.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n"
      ],
      "metadata": {
        "id": "nB6RWBl5CSWn"
      },
      "id": "nB6RWBl5CSWn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow_docs.vis import embed\n",
        "from tensorflow import keras\n",
        "from imutils import paths\n",
        "from tensorflow.keras import models\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import imageio\n",
        "import cv2\n",
        "import os"
      ],
      "metadata": {
        "id": "6qHQWhPBCbya"
      },
      "id": "6qHQWhPBCbya",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters\n",
        "IMG_SIZE = 64\n",
        "BATCH_SIZE = 30\n",
        "EPOCHS = 100\n",
        "NUM_CLASSES = 2"
      ],
      "metadata": {
        "id": "O2r3YhtqCgtR"
      },
      "id": "O2r3YhtqCgtR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **모델 구현**"
      ],
      "metadata": {
        "id": "Y8jgUUnztfuC"
      },
      "id": "Y8jgUUnztfuC"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "# reshape input data appropriately for the GRU layer\n",
        "# Flatten spatial dimensions\n",
        "\n",
        "X_train_flat = X_train.reshape((X_train.shape[0], -1, X_train.shape[-1]))\n",
        "X_val_flat = X_val.reshape((X_val.shape[0], -1, X_val.shape[-1]))\n",
        "X_test_flat = X_test.reshape((X_test.shape[0], -1, X_test.shape[-1]))\n",
        "\n",
        "# Utility for our sequence model.\n",
        "def get_model(input_shape, num_classes):\n",
        "    frame_features_input = keras.Input(shape=(X_train_flat.shape[1], X_train_flat.shape[2]))\n",
        "\n",
        "    # Add a Convolutional layer for spatial feature extraction\n",
        "    x = layers.Conv1D(32, kernel_size=3, activation='relu')(frame_features_input)\n",
        "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    # ADD RNN\n",
        "    x = layers.GRU(16)(frame_features_input)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(64, activation=\"relu\")(x)\n",
        "    output = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    cnn_rnn_model = keras.Model(inputs=frame_features_input, outputs=output)\n",
        "\n",
        "    cnn_rnn_model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return cnn_rnn_model\n",
        "\n",
        "input_shape = (64, 64, 3)\n",
        "num_classes = 2  # Binary classification for patients and controls\n",
        "\n",
        "# Example usage\n",
        "cnn_rnn_model = get_model(input_shape, num_classes)\n",
        "cnn_rnn_model.summary()\n",
        "\n",
        "# Utility for running experiments.\n",
        "def run_experiment():\n",
        "    filepath = \"/tmp/video_classifier\"\n",
        "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "        filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
        "    )\n",
        "\n",
        "    pa_model = get_model(input_shape, num_classes)  # Pass input_shape and num_classes to the function\n",
        "    history = pa_model.fit(\n",
        "        X_train_flat,  # Use X_train_flat instead of X_train\n",
        "        y_train,\n",
        "        validation_split=0.5,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=[checkpoint],\n",
        "    )\n",
        "\n",
        "    #pa_model.load_weights(filepath)\n",
        "    _, accuracy = pa_model.evaluate(X_test_flat, y_test)  # Use X_test_flat instead of X_test\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history, pa_model\n",
        "\n",
        "_, pa_model = run_experiment()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfAidPfZgz9z",
        "outputId": "34c553b4-bac6-4edd-d530-ca69db450852"
      },
      "id": "gfAidPfZgz9z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 64, 64)]          0         \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 16)                3936      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                1088      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5154 (20.13 KB)\n",
            "Trainable params: 5154 (20.13 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7319 - accuracy: 0.4856\n",
            "Epoch 1: val_loss improved from inf to 0.69523, saving model to /tmp/video_classifier\n",
            "9/9 [==============================] - 5s 206ms/step - loss: 0.7319 - accuracy: 0.4856 - val_loss: 0.6952 - val_accuracy: 0.4532\n",
            "Epoch 2/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.6868 - accuracy: 0.5469\n",
            "Epoch 2: val_loss improved from 0.69523 to 0.68988, saving model to /tmp/video_classifier\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.6884 - accuracy: 0.5396 - val_loss: 0.6899 - val_accuracy: 0.5504\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7023 - accuracy: 0.5000\n",
            "Epoch 3: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.7023 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.4928\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7031 - accuracy: 0.4928\n",
            "Epoch 4: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.7031 - accuracy: 0.4928 - val_loss: 0.6967 - val_accuracy: 0.4496\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7029 - accuracy: 0.4856\n",
            "Epoch 5: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.7029 - accuracy: 0.4856 - val_loss: 0.6900 - val_accuracy: 0.5504\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7000 - accuracy: 0.4856\n",
            "Epoch 6: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.7000 - accuracy: 0.4856 - val_loss: 0.6915 - val_accuracy: 0.5612\n",
            "Epoch 7/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.6881 - accuracy: 0.5469\n",
            "Epoch 7: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.6861 - accuracy: 0.5576 - val_loss: 0.6933 - val_accuracy: 0.5144\n",
            "Epoch 8/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.7081 - accuracy: 0.4961\n",
            "Epoch 8: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 0.7072 - accuracy: 0.5000 - val_loss: 0.6990 - val_accuracy: 0.4424\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6944 - accuracy: 0.4964\n",
            "Epoch 9: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.6944 - accuracy: 0.4964 - val_loss: 0.6952 - val_accuracy: 0.4496\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.4928\n",
            "Epoch 10: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 62ms/step - loss: 0.6939 - accuracy: 0.4928 - val_loss: 0.7004 - val_accuracy: 0.4532\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6855 - accuracy: 0.5540\n",
            "Epoch 11: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.6855 - accuracy: 0.5540 - val_loss: 0.6981 - val_accuracy: 0.4460\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6916 - accuracy: 0.5180\n",
            "Epoch 12: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.6916 - accuracy: 0.5180 - val_loss: 0.6923 - val_accuracy: 0.5576\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6962 - accuracy: 0.5396\n",
            "Epoch 13: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.6962 - accuracy: 0.5396 - val_loss: 0.6951 - val_accuracy: 0.4496\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6997 - accuracy: 0.5000\n",
            "Epoch 14: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.6997 - accuracy: 0.5000 - val_loss: 0.6974 - val_accuracy: 0.4496\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6992 - accuracy: 0.5108\n",
            "Epoch 15: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.6992 - accuracy: 0.5108 - val_loss: 0.6950 - val_accuracy: 0.4460\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5180\n",
            "Epoch 16: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.6932 - accuracy: 0.5180 - val_loss: 0.6908 - val_accuracy: 0.5612\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.5036\n",
            "Epoch 17: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.6939 - accuracy: 0.5036 - val_loss: 0.6923 - val_accuracy: 0.5540\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7059 - accuracy: 0.5180\n",
            "Epoch 18: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.7059 - accuracy: 0.5180 - val_loss: 0.7003 - val_accuracy: 0.4496\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6947 - accuracy: 0.5252\n",
            "Epoch 19: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.6947 - accuracy: 0.5252 - val_loss: 0.6998 - val_accuracy: 0.4496\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6943 - accuracy: 0.4820\n",
            "Epoch 20: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 0.6943 - accuracy: 0.4820 - val_loss: 0.6926 - val_accuracy: 0.5216\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6883 - accuracy: 0.5468\n",
            "Epoch 21: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.6883 - accuracy: 0.5468 - val_loss: 0.6922 - val_accuracy: 0.5432\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6999 - accuracy: 0.5000\n",
            "Epoch 22: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.6999 - accuracy: 0.5000 - val_loss: 0.6960 - val_accuracy: 0.4353\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7006 - accuracy: 0.4964\n",
            "Epoch 23: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.7006 - accuracy: 0.4964 - val_loss: 0.7021 - val_accuracy: 0.4496\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6960 - accuracy: 0.5072\n",
            "Epoch 24: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.6960 - accuracy: 0.5072 - val_loss: 0.6994 - val_accuracy: 0.4496\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7023 - accuracy: 0.4856\n",
            "Epoch 25: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.7023 - accuracy: 0.4856 - val_loss: 0.6989 - val_accuracy: 0.4496\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6889 - accuracy: 0.5396\n",
            "Epoch 26: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.6889 - accuracy: 0.5396 - val_loss: 0.6963 - val_accuracy: 0.4496\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6906 - accuracy: 0.5252\n",
            "Epoch 27: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.6906 - accuracy: 0.5252 - val_loss: 0.6979 - val_accuracy: 0.4496\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7062 - accuracy: 0.4460\n",
            "Epoch 28: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.7062 - accuracy: 0.4460 - val_loss: 0.6927 - val_accuracy: 0.5288\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5108\n",
            "Epoch 29: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.6931 - accuracy: 0.5108 - val_loss: 0.6963 - val_accuracy: 0.4496\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5000\n",
            "Epoch 30: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.6927 - accuracy: 0.5000 - val_loss: 0.6935 - val_accuracy: 0.4856\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6923 - accuracy: 0.4964\n",
            "Epoch 31: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.6923 - accuracy: 0.4964 - val_loss: 0.6946 - val_accuracy: 0.4388\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5216\n",
            "Epoch 32: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 50ms/step - loss: 0.6932 - accuracy: 0.5216 - val_loss: 0.6963 - val_accuracy: 0.4460\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6989 - accuracy: 0.4856\n",
            "Epoch 33: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.6989 - accuracy: 0.4856 - val_loss: 0.6965 - val_accuracy: 0.4424\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6910 - accuracy: 0.5108\n",
            "Epoch 34: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.6910 - accuracy: 0.5108 - val_loss: 0.6948 - val_accuracy: 0.4568\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6972 - accuracy: 0.4784\n",
            "Epoch 35: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.6972 - accuracy: 0.4784 - val_loss: 0.6965 - val_accuracy: 0.4748\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6900 - accuracy: 0.5216\n",
            "Epoch 36: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 49ms/step - loss: 0.6900 - accuracy: 0.5216 - val_loss: 0.6944 - val_accuracy: 0.4784\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7004 - accuracy: 0.5036\n",
            "Epoch 37: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.7004 - accuracy: 0.5036 - val_loss: 0.6947 - val_accuracy: 0.4964\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6898 - accuracy: 0.5288\n",
            "Epoch 38: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.6898 - accuracy: 0.5288 - val_loss: 0.6970 - val_accuracy: 0.4748\n",
            "Epoch 39/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.6930 - accuracy: 0.4648\n",
            "Epoch 39: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 68ms/step - loss: 0.6919 - accuracy: 0.4712 - val_loss: 0.6973 - val_accuracy: 0.4676\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5252\n",
            "Epoch 40: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.6931 - accuracy: 0.5252 - val_loss: 0.6929 - val_accuracy: 0.5108\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6895 - accuracy: 0.5252\n",
            "Epoch 41: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 63ms/step - loss: 0.6895 - accuracy: 0.5252 - val_loss: 0.6937 - val_accuracy: 0.4928\n",
            "Epoch 42/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.6921 - accuracy: 0.5352\n",
            "Epoch 42: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.6922 - accuracy: 0.5360 - val_loss: 0.6940 - val_accuracy: 0.4640\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6907 - accuracy: 0.5072\n",
            "Epoch 43: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.6907 - accuracy: 0.5072 - val_loss: 0.6952 - val_accuracy: 0.4568\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6982 - accuracy: 0.5000\n",
            "Epoch 44: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.6982 - accuracy: 0.5000 - val_loss: 0.6914 - val_accuracy: 0.5468\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6914 - accuracy: 0.5180\n",
            "Epoch 45: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.6914 - accuracy: 0.5180 - val_loss: 0.6922 - val_accuracy: 0.5180\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6891 - accuracy: 0.5468\n",
            "Epoch 46: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.6891 - accuracy: 0.5468 - val_loss: 0.7092 - val_accuracy: 0.4496\n",
            "Epoch 47/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.6944 - accuracy: 0.5234\n",
            "Epoch 47: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 67ms/step - loss: 0.6942 - accuracy: 0.5252 - val_loss: 0.6969 - val_accuracy: 0.4568\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6908 - accuracy: 0.5072\n",
            "Epoch 48: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.6908 - accuracy: 0.5072 - val_loss: 0.6939 - val_accuracy: 0.5144\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6933 - accuracy: 0.5108\n",
            "Epoch 49: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.6933 - accuracy: 0.5108 - val_loss: 0.6905 - val_accuracy: 0.5360\n",
            "Epoch 50/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.6855 - accuracy: 0.5625\n",
            "Epoch 50: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.6860 - accuracy: 0.5612 - val_loss: 0.6941 - val_accuracy: 0.5144\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6847 - accuracy: 0.5540\n",
            "Epoch 51: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.6847 - accuracy: 0.5540 - val_loss: 0.6930 - val_accuracy: 0.5108\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6972 - accuracy: 0.4892\n",
            "Epoch 52: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.6972 - accuracy: 0.4892 - val_loss: 0.6909 - val_accuracy: 0.5504\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6921 - accuracy: 0.5432\n",
            "Epoch 53: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.6921 - accuracy: 0.5432 - val_loss: 0.6963 - val_accuracy: 0.4281\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6973 - accuracy: 0.5216\n",
            "Epoch 54: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.6973 - accuracy: 0.5216 - val_loss: 0.6967 - val_accuracy: 0.4281\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6907 - accuracy: 0.5360\n",
            "Epoch 55: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.6907 - accuracy: 0.5360 - val_loss: 0.6952 - val_accuracy: 0.5036\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6896 - accuracy: 0.5396\n",
            "Epoch 56: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.6896 - accuracy: 0.5396 - val_loss: 0.6917 - val_accuracy: 0.5360\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6905 - accuracy: 0.5288\n",
            "Epoch 57: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.6905 - accuracy: 0.5288 - val_loss: 0.6942 - val_accuracy: 0.5144\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6943 - accuracy: 0.5288\n",
            "Epoch 58: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.6943 - accuracy: 0.5288 - val_loss: 0.6986 - val_accuracy: 0.4496\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6922 - accuracy: 0.5288\n",
            "Epoch 59: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.6922 - accuracy: 0.5288 - val_loss: 0.6992 - val_accuracy: 0.4460\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.5432\n",
            "Epoch 60: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 0.6937 - accuracy: 0.5432 - val_loss: 0.6960 - val_accuracy: 0.4496\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6879 - accuracy: 0.5432\n",
            "Epoch 61: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.6879 - accuracy: 0.5432 - val_loss: 0.6977 - val_accuracy: 0.4353\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6910 - accuracy: 0.5144\n",
            "Epoch 62: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.6910 - accuracy: 0.5144 - val_loss: 0.6914 - val_accuracy: 0.5432\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6915 - accuracy: 0.5288\n",
            "Epoch 63: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.6915 - accuracy: 0.5288 - val_loss: 0.6928 - val_accuracy: 0.5216\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6887 - accuracy: 0.4928\n",
            "Epoch 64: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.6887 - accuracy: 0.4928 - val_loss: 0.7029 - val_accuracy: 0.4424\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.5288\n",
            "Epoch 65: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.6937 - accuracy: 0.5288 - val_loss: 0.7024 - val_accuracy: 0.4604\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6942 - accuracy: 0.5072\n",
            "Epoch 66: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.6942 - accuracy: 0.5072 - val_loss: 0.6927 - val_accuracy: 0.5072\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6782 - accuracy: 0.6223\n",
            "Epoch 67: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.6782 - accuracy: 0.6223 - val_loss: 0.7009 - val_accuracy: 0.4532\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6915 - accuracy: 0.5180\n",
            "Epoch 68: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.6915 - accuracy: 0.5180 - val_loss: 0.7046 - val_accuracy: 0.4640\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6916 - accuracy: 0.5216\n",
            "Epoch 69: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.6916 - accuracy: 0.5216 - val_loss: 0.6952 - val_accuracy: 0.4496\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.5396\n",
            "Epoch 70: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.6934 - accuracy: 0.5396 - val_loss: 0.7171 - val_accuracy: 0.4496\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.7016 - accuracy: 0.5036\n",
            "Epoch 71: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.7016 - accuracy: 0.5036 - val_loss: 0.7069 - val_accuracy: 0.4460\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6830 - accuracy: 0.5540\n",
            "Epoch 72: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.6830 - accuracy: 0.5540 - val_loss: 0.6988 - val_accuracy: 0.4604\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6970 - accuracy: 0.5072\n",
            "Epoch 73: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.6970 - accuracy: 0.5072 - val_loss: 0.7036 - val_accuracy: 0.4496\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6919 - accuracy: 0.5576\n",
            "Epoch 74: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.6919 - accuracy: 0.5576 - val_loss: 0.7042 - val_accuracy: 0.4460\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.4856\n",
            "Epoch 75: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.6935 - accuracy: 0.4856 - val_loss: 0.7010 - val_accuracy: 0.4460\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6943 - accuracy: 0.5468\n",
            "Epoch 76: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 49ms/step - loss: 0.6943 - accuracy: 0.5468 - val_loss: 0.7021 - val_accuracy: 0.4568\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6877 - accuracy: 0.5468\n",
            "Epoch 77: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.6877 - accuracy: 0.5468 - val_loss: 0.7038 - val_accuracy: 0.4568\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6873 - accuracy: 0.5540\n",
            "Epoch 78: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.6873 - accuracy: 0.5540 - val_loss: 0.6981 - val_accuracy: 0.4676\n",
            "Epoch 79/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.6904 - accuracy: 0.5195\n",
            "Epoch 79: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 62ms/step - loss: 0.6892 - accuracy: 0.5324 - val_loss: 0.6996 - val_accuracy: 0.4568\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6846 - accuracy: 0.5396\n",
            "Epoch 80: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.6846 - accuracy: 0.5396 - val_loss: 0.6969 - val_accuracy: 0.4748\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6911 - accuracy: 0.5396\n",
            "Epoch 81: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.6911 - accuracy: 0.5396 - val_loss: 0.6993 - val_accuracy: 0.4568\n",
            "Epoch 82/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.6909 - accuracy: 0.5625\n",
            "Epoch 82: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.6875 - accuracy: 0.5755 - val_loss: 0.6990 - val_accuracy: 0.4640\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6845 - accuracy: 0.5468\n",
            "Epoch 83: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 63ms/step - loss: 0.6845 - accuracy: 0.5468 - val_loss: 0.7018 - val_accuracy: 0.4640\n",
            "Epoch 84/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.6888 - accuracy: 0.5469\n",
            "Epoch 84: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.6865 - accuracy: 0.5540 - val_loss: 0.7025 - val_accuracy: 0.4460\n",
            "Epoch 85/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.6910 - accuracy: 0.5508\n",
            "Epoch 85: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.6900 - accuracy: 0.5504 - val_loss: 0.7040 - val_accuracy: 0.4712\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6830 - accuracy: 0.5719\n",
            "Epoch 86: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 67ms/step - loss: 0.6830 - accuracy: 0.5719 - val_loss: 0.6962 - val_accuracy: 0.4712\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6909 - accuracy: 0.5144\n",
            "Epoch 87: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.6909 - accuracy: 0.5144 - val_loss: 0.7021 - val_accuracy: 0.4712\n",
            "Epoch 88/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.6927 - accuracy: 0.5234\n",
            "Epoch 88: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.6915 - accuracy: 0.5288 - val_loss: 0.6989 - val_accuracy: 0.4604\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6823 - accuracy: 0.5432\n",
            "Epoch 89: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.6823 - accuracy: 0.5432 - val_loss: 0.6958 - val_accuracy: 0.4784\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6882 - accuracy: 0.5432\n",
            "Epoch 90: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 0.6882 - accuracy: 0.5432 - val_loss: 0.7002 - val_accuracy: 0.4604\n",
            "Epoch 91/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.6866 - accuracy: 0.5391\n",
            "Epoch 91: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.6868 - accuracy: 0.5360 - val_loss: 0.7195 - val_accuracy: 0.4496\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6837 - accuracy: 0.5612\n",
            "Epoch 92: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.6837 - accuracy: 0.5612 - val_loss: 0.6967 - val_accuracy: 0.4640\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6966 - accuracy: 0.5396\n",
            "Epoch 93: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.6966 - accuracy: 0.5396 - val_loss: 0.6934 - val_accuracy: 0.4928\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6863 - accuracy: 0.5360\n",
            "Epoch 94: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.6863 - accuracy: 0.5360 - val_loss: 0.7172 - val_accuracy: 0.4568\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6988 - accuracy: 0.5072\n",
            "Epoch 95: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.6988 - accuracy: 0.5072 - val_loss: 0.7250 - val_accuracy: 0.4496\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6852 - accuracy: 0.5396\n",
            "Epoch 96: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.6852 - accuracy: 0.5396 - val_loss: 0.6976 - val_accuracy: 0.4640\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6941 - accuracy: 0.5180\n",
            "Epoch 97: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.6941 - accuracy: 0.5180 - val_loss: 0.7041 - val_accuracy: 0.4496\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6831 - accuracy: 0.5612\n",
            "Epoch 98: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.6831 - accuracy: 0.5612 - val_loss: 0.7097 - val_accuracy: 0.4568\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6900 - accuracy: 0.5540\n",
            "Epoch 99: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.6900 - accuracy: 0.5540 - val_loss: 0.7043 - val_accuracy: 0.4496\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.6832 - accuracy: 0.5468\n",
            "Epoch 100: val_loss did not improve from 0.68988\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.6832 - accuracy: 0.5468 - val_loss: 0.7016 - val_accuracy: 0.4604\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6824 - accuracy: 0.6286\n",
            "Test accuracy: 62.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **결과 분석**"
      ],
      "metadata": {
        "id": "ElADOMBOuIHN"
      },
      "id": "ElADOMBOuIHN"
    },
    {
      "cell_type": "code",
      "source": [
        "#Building the Decision Tree Model on our dataset\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "predicted = pa_model.predict(X_test_flat)"
      ],
      "metadata": {
        "id": "GHw1Az2YPhme",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e03aba9-d171-4167-8cf4-30c9ccbf1451"
      },
      "id": "GHw1Az2YPhme",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 10ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wkp04Vs8QRZT",
        "outputId": "55503789-16bd-472f-b20d-5bd9825a632a"
      },
      "id": "Wkp04Vs8QRZT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.48067036, 0.51932967],\n",
              "       [0.51801836, 0.4819816 ],\n",
              "       [0.5136643 , 0.4863358 ],\n",
              "       [0.46301937, 0.53698057],\n",
              "       [0.48880187, 0.5111981 ],\n",
              "       [0.4714541 , 0.52854586],\n",
              "       [0.509095  , 0.49090502],\n",
              "       [0.48172498, 0.518275  ],\n",
              "       [0.47736123, 0.5226388 ],\n",
              "       [0.5028061 , 0.49719387],\n",
              "       [0.45665616, 0.54334384],\n",
              "       [0.48718554, 0.5128145 ],\n",
              "       [0.4687301 , 0.53126997],\n",
              "       [0.49568707, 0.50431293],\n",
              "       [0.47624114, 0.5237589 ],\n",
              "       [0.48407954, 0.51592046],\n",
              "       [0.4796244 , 0.5203756 ],\n",
              "       [0.48629558, 0.5137045 ],\n",
              "       [0.48003438, 0.51996565],\n",
              "       [0.47202194, 0.52797794],\n",
              "       [0.48606405, 0.51393586],\n",
              "       [0.48100013, 0.5189998 ],\n",
              "       [0.4835552 , 0.51644474],\n",
              "       [0.49938995, 0.50061   ],\n",
              "       [0.49078906, 0.50921094],\n",
              "       [0.49469256, 0.5053074 ],\n",
              "       [0.488085  , 0.5119149 ],\n",
              "       [0.4796999 , 0.5203001 ],\n",
              "       [0.47758642, 0.5224136 ],\n",
              "       [0.53309095, 0.46690908],\n",
              "       [0.5393109 , 0.46068907],\n",
              "       [0.47981697, 0.52018297],\n",
              "       [0.48126277, 0.5187371 ],\n",
              "       [0.49764392, 0.50235605],\n",
              "       [0.5273141 , 0.47268584],\n",
              "       [0.5051275 , 0.49487248],\n",
              "       [0.47986743, 0.52013254],\n",
              "       [0.48032433, 0.5196757 ],\n",
              "       [0.49859983, 0.50140023],\n",
              "       [0.4803114 , 0.5196886 ],\n",
              "       [0.4760793 , 0.5239207 ],\n",
              "       [0.48382464, 0.5161753 ],\n",
              "       [0.4715992 , 0.5284008 ],\n",
              "       [0.46798202, 0.53201795],\n",
              "       [0.5121355 , 0.48786438],\n",
              "       [0.5368658 , 0.4631343 ],\n",
              "       [0.46115163, 0.5388483 ],\n",
              "       [0.4831315 , 0.51686835],\n",
              "       [0.47052178, 0.5294782 ],\n",
              "       [0.48894942, 0.5110505 ],\n",
              "       [0.48749754, 0.5125025 ],\n",
              "       [0.47019747, 0.52980256],\n",
              "       [0.4754673 , 0.52453274],\n",
              "       [0.5134639 , 0.4865361 ],\n",
              "       [0.5014979 , 0.49850208],\n",
              "       [0.47969508, 0.52030486],\n",
              "       [0.48890954, 0.5110904 ],\n",
              "       [0.4823558 , 0.5176443 ],\n",
              "       [0.4876394 , 0.5123606 ],\n",
              "       [0.48234257, 0.51765734],\n",
              "       [0.4825176 , 0.51748246],\n",
              "       [0.47889337, 0.52110654],\n",
              "       [0.49960682, 0.50039303],\n",
              "       [0.47719157, 0.52280843],\n",
              "       [0.486923  , 0.513077  ],\n",
              "       [0.47929436, 0.5207057 ],\n",
              "       [0.48717102, 0.51282895],\n",
              "       [0.47800618, 0.52199376],\n",
              "       [0.4805504 , 0.5194496 ],\n",
              "       [0.48266718, 0.5173328 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_rows = predicted.shape[0]\n",
        "print(num_rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shYrkBAP_Qjd",
        "outputId": "89fa9195-27e3-4de1-cfbc-66c3c91deef1"
      },
      "id": "shYrkBAP_Qjd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 행에서 더 큰 값의 인덱스를 추출하여 1 또는 0으로 구성된 리스트 생성\n",
        "predicted_classes = (predicted[:, 1] > predicted[:, 0]).astype(int)\n",
        "\n",
        "# 결과 출력\n",
        "print(predicted_classes)\n",
        "print(len(predicted_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYJZmNlRhJRv",
        "outputId": "50fe48ff-351c-46ee-bd3d-ce07a3856fff"
      },
      "id": "VYJZmNlRhJRv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1\n",
            " 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, predicted_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvqPkDiMkdAq",
        "outputId": "abf61791-4503-4516-fcd3-3214c96dcb53"
      },
      "id": "AvqPkDiMkdAq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.28      0.41        32\n",
            "           1       0.60      0.92      0.73        38\n",
            "\n",
            "    accuracy                           0.63        70\n",
            "   macro avg       0.68      0.60      0.57        70\n",
            "weighted avg       0.67      0.63      0.58        70\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plot the confusion matrix\n",
        "mat = confusion_matrix(y_test, predicted_classes)\n",
        "sns.heatmap(mat.T, square = True, annot=True, xticklabels = sorted(set(y_test)), yticklabels = sorted(set(y_test)), fmt = \"d\")\n",
        "plt.xlabel(\"true labels\")\n",
        "plt.ylabel(\"predicted label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7PIXTsDnzXXH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "69c2a713-894c-4a40-aecc-a88549abeb32"
      },
      "id": "7PIXTsDnzXXH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}